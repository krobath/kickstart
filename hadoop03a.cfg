#platform=x86, AMD64, or Intel EM64T
#version=DEVEL
# Firewall configuration
firewall --disabled
# Install OS instead of upgrade
install
# Use CDROM installation media
cdrom
#url --url=http://192.168.1.21/installables/repo/oel74
#url --url http://192.168.1.21/installables/repo/oel74
# Root password
rootpw --iscrypted $1$WmKxrlR8$EoRKlhpInteg3CHkB69PT1
# System authorization information
auth  --useshadow  --passalgo=sha512
# Use graphical install
graphical
firstboot --disable
# System keyboard
keyboard dk
# System language
lang en_US
# SELinux configuration
selinux --disabled
# Installation logging level
logging --level=info

# System timezone
timezone  Europe/Copenhagen

# Network information
network  --bootproto=static --device=ens192 --gateway=192.168.1.1 --ip=192.168.1.123 --nameserver=192.168.1.1,192.168.1.11 --netmask=255.255.255.0 --onboot=on --hostname=hadoop03.krobath.local
#network  --bootproto=static --device=eth1 --ip=10.1.1.121 --netmask=255.255.255.0 --onboot=on

# System bootloader configuration
bootloader --location=mbr  --driveorder="sda,sdb,sdc,sdd,sde"

# Partition clearing information
clearpart --all --drives=sda,sdb,sdc,sdd,sde

part /boot --fstype=ext4 --size=500 --ondisk=sda
part pv.pv_root --grow --size=1 --ondisk=sda

volgroup vg01 --pesize=4096 pv.pv_root
logvol / --fstype=ext4 --name=lv_root --vgname=vg01 --grow --size=1024 --maxsize=30720
logvol swap --name=lv_swap --vgname=vg01 --grow --size=4096 --maxsize=8192

# create the hadoop partitions
part pv.11 --size=1 --grow --ondisk=sdb
part pv.12 --size=1 --grow --ondisk=sdc
part pv.13 --size=1 --grow --ondisk=sdd
part pv.14 --size=1 --grow --ondisk=sde


%packages
@base
@^Server with GUI
@compat-libraries
@console-internet
@development
@fonts
@internet-browser
@graphical-admin-tools
@network-tools
@performance
@perl-runtime
@system-admin-tools
@x11
@system-management
lsscsi
gcc
nfs-utils
ksh
dos2unix
%end

#Post-installation script

%post

# Create /data mountpoint for Hadoop
vgcreate vg02 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1
lvcreate -l 100%FREE --stripes 4 --stripesize 4096 --name lv_data vg02
mkfs.ext4 -b 4096 -E stride=128,stripe-width=128 /dev/vg02/lv_data
mkdir -p /data
echo "/dev/mapper/vg02-lv_data     /data ext4   discard, noatime,nodiratime 1 2" >> /etc/fstab


# Create hadoop user
useradd -c "Hadoop Owner" -d /home/hadoop -m hadoop

# Set hadoop user password
echo zaq12wsx | passwd --stdin hadoop
 
chown hadoop:users /data


# Disable Redhat 7 firewall
service firewalld stop
systemctl disable firewalld


# Update fstab to mount /shared
mkdir /shared
chmod 777 /shared
echo "192.168.1.21:/volume2/shared       /shared   nfs     rsize=8192,wsize=8192,timeo=14,intr" >> /etc/fstab
mount /shared


# Update /etc/hosts
echo "" >> /etc/hosts
echo "## Added by Hadoop kickstart script - do not change!" >> /etc/hosts
echo "# HDFS nodes" >> /etc/hosts
echo "192.168.1.121	hadoop01.krobath.local	hadoop01" >> /etc/hosts
echo "192.168.1.122	hadoop02.krobath.local	hadoop02" >> /etc/hosts
echo "192.168.1.123	hadoop03.krobath.local	hadoop03" >> /etc/hosts


#
# Install Java
#
#rpm -Uvh /shared/Java/jdk-10.0.1_linux-x64_bin.rpm

%end